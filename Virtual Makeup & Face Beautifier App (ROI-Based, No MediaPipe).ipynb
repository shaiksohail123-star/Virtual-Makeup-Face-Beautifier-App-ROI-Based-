{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "197b6e66-5c86-4838-9d5e-10dc6e9e787e",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'streamlit'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[6]\u001b[39m\u001b[32m, line 3\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mcv2\u001b[39;00m\n\u001b[32m      2\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnumpy\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnp\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mstreamlit\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mst\u001b[39;00m\n\u001b[32m      4\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mPIL\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Image\n\u001b[32m      6\u001b[39m st.set_page_config(page_title=\u001b[33m\"\u001b[39m\u001b[33mðŸ’„ Virtual Makeup App\u001b[39m\u001b[33m\"\u001b[39m, layout=\u001b[33m\"\u001b[39m\u001b[33mwide\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'streamlit'"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import streamlit as st\n",
    "from PIL import Image\n",
    "\n",
    "st.set_page_config(page_title=\"ðŸ’„ Virtual Makeup App\", layout=\"wide\")\n",
    "\n",
    "st.title(\"ðŸ’„ Virtual Makeup / Face Beautifier App (ROI-Based)\")\n",
    "st.write(\"\"\"\n",
    "This Streamlit app applies simple virtual makeup effects (lipstick, blush, and smoothing)\n",
    "using **OpenCV** â€” without Mediapipe.\n",
    "\"\"\")\n",
    "\n",
    "# Sidebar controls\n",
    "st.sidebar.header(\"ðŸŽ¨ Makeup Controls\")\n",
    "lip_intensity = st.sidebar.slider(\"ðŸ’‹ Lipstick Intensity\", 0, 100, 50)\n",
    "blush_intensity = st.sidebar.slider(\"ðŸŒ¸ Blush Intensity\", 0, 100, 50)\n",
    "smooth_intensity = st.sidebar.slider(\"âœ¨ Skin Smoothing\", 0, 100, 30)\n",
    "upload_option = st.sidebar.radio(\"Select Input Type\", [\"Use Webcam\", \"Upload Image\"])\n",
    "\n",
    "# Load Haar Cascade\n",
    "face_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml')\n",
    "\n",
    "def apply_makeup(img):\n",
    "    \"\"\"Apply lipstick, blush, and smoothing effect to face ROI.\"\"\"\n",
    "    img_out = img.copy()\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    faces = face_cascade.detectMultiScale(gray, 1.3, 5)\n",
    "\n",
    "    for (x, y, w, h) in faces:\n",
    "        face_roi = img_out[y:y+h, x:x+w]\n",
    "\n",
    "        # Lipstick (bottom quarter of face)\n",
    "        lip_area = face_roi[int(0.75*h):, :]\n",
    "        lip_overlay = np.full_like(lip_area, (0, 0, 255))\n",
    "        cv2.addWeighted(lip_overlay, lip_intensity/100, lip_area, 1 - lip_intensity/100, 0, lip_area)\n",
    "\n",
    "        # Blush (two side circles)\n",
    "        blush_color = (147, 20, 255)\n",
    "        radius = w // 10\n",
    "        cv2.circle(face_roi, (int(w*0.3), int(h*0.6)), radius, blush_color, -1)\n",
    "        cv2.circle(face_roi, (int(w*0.7), int(h*0.6)), radius, blush_color, -1)\n",
    "        overlay = face_roi.copy()\n",
    "        alpha = blush_intensity / 100\n",
    "        cv2.addWeighted(overlay, alpha, face_roi, 1 - alpha, 0, face_roi)\n",
    "\n",
    "        # Skin smoothing\n",
    "        if smooth_intensity > 0:\n",
    "            smoothed = cv2.bilateralFilter(face_roi, 15, 75, 75)\n",
    "            cv2.addWeighted(smoothed, smooth_intensity/100, face_roi, 1 - smooth_intensity/100, 0, face_roi)\n",
    "\n",
    "    return img_out\n",
    "\n",
    "if upload_option == \"Upload Image\":\n",
    "    uploaded_file = st.file_uploader(\"Upload an image\", type=[\"jpg\", \"jpeg\", \"png\"])\n",
    "    if uploaded_file is not None:\n",
    "        image = np.array(Image.open(uploaded_file))\n",
    "        st.image(image, caption=\"Original Image\", use_container_width=True)\n",
    "        result = apply_makeup(cv2.cvtColor(image, cv2.COLOR_RGB2BGR))\n",
    "        st.image(cv2.cvtColor(result, cv2.COLOR_BGR2RGB), caption=\"With Virtual Makeup\", use_container_width=True)\n",
    "else:\n",
    "    st.write(\"ðŸ“· Using webcam. Click 'Start' below to begin.\")\n",
    "    run = st.button(\"Start Webcam\")\n",
    "\n",
    "    if run:\n",
    "        cap = cv2.VideoCapture(0)\n",
    "        stframe = st.empty()\n",
    "        while True:\n",
    "            ret, frame = cap.read()\n",
    "            if not ret:\n",
    "                st.error(\"Camera not accessible.\")\n",
    "                break\n",
    "            frame = cv2.flip(frame, 1)\n",
    "            result = apply_makeup(frame)\n",
    "            stframe.image(cv2.cvtColor(result, cv2.COLOR_BGR2RGB), channels=\"RGB\")\n",
    "        cap.release()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "72a6b04b-dcf5-42ab-bbcc-1f12fde19436",
   "metadata": {},
   "outputs": [
    {
     "ename": "error",
     "evalue": "OpenCV(4.12.0) D:\\a\\opencv-python\\opencv-python\\opencv\\modules\\objdetect\\src\\cascadedetect.cpp:1689: error: (-215:Assertion failed) !empty() in function 'cv::CascadeClassifier::detectMultiScale'\n",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31merror\u001b[39m                                     Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[7]\u001b[39m\u001b[32m, line 74\u001b[39m\n\u001b[32m     71\u001b[39m frame = cv2.flip(frame, \u001b[32m1\u001b[39m)\n\u001b[32m     72\u001b[39m gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n\u001b[32m---> \u001b[39m\u001b[32m74\u001b[39m faces = \u001b[43mface_cascade\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdetectMultiScale\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgray\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m1.3\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m5\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m     76\u001b[39m lip_int = cv2.getTrackbarPos(\u001b[33m'\u001b[39m\u001b[33mLip Intensity\u001b[39m\u001b[33m'\u001b[39m, WINDOW_NAME)\n\u001b[32m     77\u001b[39m blush_int = cv2.getTrackbarPos(\u001b[33m'\u001b[39m\u001b[33mBlush Intensity\u001b[39m\u001b[33m'\u001b[39m, WINDOW_NAME)\n",
      "\u001b[31merror\u001b[39m: OpenCV(4.12.0) D:\\a\\opencv-python\\opencv-python\\opencv\\modules\\objdetect\\src\\cascadedetect.cpp:1689: error: (-215:Assertion failed) !empty() in function 'cv::CascadeClassifier::detectMultiScale'\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Virtual Makeup / Face Beautifier App (ROI-Based, No MediaPipe)\n",
    "--------------------------------------------------------------\n",
    "Features:\n",
    "- Detect face using Haar Cascade\n",
    "- Apply simple ROI-based lipstick, blush, and eye shadow\n",
    "- Adjustable intensity using trackbars\n",
    "- Toggle effects with keys:\n",
    "    'l' - toggle lipstick\n",
    "    'b' - toggle blush\n",
    "    'e' - toggle eyeshadow\n",
    "    's' - save image\n",
    "    'q' - quit\n",
    "\n",
    "Dependencies:\n",
    "    pip install opencv-python numpy\n",
    "\"\"\"\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "# Load face detector\n",
    "face_cascade = cv2.CascadeClassifier('haarcascade_frontalface_default.xml')\n",
    "\n",
    "# Constants\n",
    "WINDOW_NAME = \"Virtual Makeup App (No MediaPipe)\"\n",
    "SAVE_PREFIX = \"virtual_makeup\"\n",
    "LIP_COLOR = (0, 0, 255)       # Red\n",
    "BLUSH_COLOR = (147, 20, 255)  # Pinkish\n",
    "EYE_COLOR = (128, 0, 128)     # Purple\n",
    "\n",
    "\n",
    "def nothing(x):\n",
    "    pass\n",
    "\n",
    "\n",
    "def apply_makeup(frame, mask, color, intensity):\n",
    "    \"\"\"Apply color on a masked region with adjustable transparency.\"\"\"\n",
    "    colored = np.zeros_like(frame)\n",
    "    colored[:] = color\n",
    "    mask = cv2.GaussianBlur(mask, (25, 25), 0)\n",
    "    alpha = (mask / 255.0) * (intensity / 100.0)\n",
    "    blended = (frame * (1 - alpha[..., None]) + colored * alpha[..., None]).astype(np.uint8)\n",
    "    return blended\n",
    "\n",
    "\n",
    "# Create trackbars\n",
    "cv2.namedWindow(WINDOW_NAME)\n",
    "cv2.createTrackbar('Lip Intensity', WINDOW_NAME, 70, 100, nothing)\n",
    "cv2.createTrackbar('Blush Intensity', WINDOW_NAME, 50, 100, nothing)\n",
    "cv2.createTrackbar('Eye Intensity', WINDOW_NAME, 60, 100, nothing)\n",
    "cv2.createTrackbar('Smoothness', WINDOW_NAME, 10, 30, nothing)\n",
    "\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "if not cap.isOpened():\n",
    "    print(\"Camera not detected!\")\n",
    "    exit()\n",
    "\n",
    "show_lip = True\n",
    "show_blush = True\n",
    "show_eye = True\n",
    "save_count = 0\n",
    "\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    frame = cv2.flip(frame, 1)\n",
    "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    faces = face_cascade.detectMultiScale(gray, 1.3, 5)\n",
    "\n",
    "    lip_int = cv2.getTrackbarPos('Lip Intensity', WINDOW_NAME)\n",
    "    blush_int = cv2.getTrackbarPos('Blush Intensity', WINDOW_NAME)\n",
    "    eye_int = cv2.getTrackbarPos('Eye Intensity', WINDOW_NAME)\n",
    "    smooth_val = cv2.getTrackbarPos('Smoothness', WINDOW_NAME)\n",
    "\n",
    "    for (x, y, w, h) in faces:\n",
    "        # Draw ROI regions\n",
    "        face_roi = frame[y:y+h, x:x+w]\n",
    "\n",
    "        # Define approximate facial regions relative to face box\n",
    "        lip_y1 = int(y + 0.7*h)\n",
    "        lip_y2 = int(y + 0.85*h)\n",
    "        lip_x1 = int(x + 0.25*w)\n",
    "        lip_x2 = int(x + 0.75*w)\n",
    "\n",
    "        cheek_y1 = int(y + 0.45*h)\n",
    "        cheek_y2 = int(y + 0.6*h)\n",
    "        left_cheek_x1 = int(x + 0.15*w)\n",
    "        left_cheek_x2 = int(x + 0.35*w)\n",
    "        right_cheek_x1 = int(x + 0.65*w)\n",
    "        right_cheek_x2 = int(x + 0.85*w)\n",
    "\n",
    "        eye_y1 = int(y + 0.25*h)\n",
    "        eye_y2 = int(y + 0.4*h)\n",
    "        left_eye_x1 = int(x + 0.2*w)\n",
    "        left_eye_x2 = int(x + 0.4*w)\n",
    "        right_eye_x1 = int(x + 0.6*w)\n",
    "        right_eye_x2 = int(x + 0.8*w)\n",
    "\n",
    "        mask = np.zeros(frame.shape[:2], np.uint8)\n",
    "\n",
    "        # Apply makeup regions\n",
    "        if show_lip:\n",
    "            cv2.rectangle(mask, (lip_x1, lip_y1), (lip_x2, lip_y2), 255, -1)\n",
    "            frame = apply_makeup(frame, mask, LIP_COLOR, lip_int)\n",
    "\n",
    "        if show_blush:\n",
    "            cv2.circle(mask, (left_cheek_x1 + 20, cheek_y1 + 20), 40, 255, -1)\n",
    "            cv2.circle(mask, (right_cheek_x1 + 60, cheek_y1 + 20), 40, 255, -1)\n",
    "            frame = apply_makeup(frame, mask, BLUSH_COLOR, blush_int)\n",
    "\n",
    "        if show_eye:\n",
    "            cv2.rectangle(mask, (left_eye_x1, eye_y1), (left_eye_x2, eye_y2), 255, -1)\n",
    "            cv2.rectangle(mask, (right_eye_x1, eye_y1), (right_eye_x2, eye_y2), 255, -1)\n",
    "            frame = apply_makeup(frame, mask, EYE_COLOR, eye_int)\n",
    "\n",
    "        # Beautify (smooth skin using bilateral filter)\n",
    "        smooth_frame = cv2.bilateralFilter(frame, smooth_val*2+1, 75, 75)\n",
    "        frame = cv2.addWeighted(frame, 0.6, smooth_frame, 0.4, 0)\n",
    "\n",
    "    cv2.putText(frame, \"Keys: l-Lips | b-Blush | e-Eyes | s-Save | q-Quit\",\n",
    "                (10, 25), cv2.FONT_HERSHEY_SIMPLEX, 0.6, (255, 255, 255), 2)\n",
    "\n",
    "    cv2.imshow(WINDOW_NAME, frame)\n",
    "    key = cv2.waitKey(1) & 0xFF\n",
    "\n",
    "    if key == ord('q'):\n",
    "        break\n",
    "    elif key == ord('l'):\n",
    "        show_lip = not show_lip\n",
    "    elif key == ord('b'):\n",
    "        show_blush = not show_blush\n",
    "    elif key == ord('e'):\n",
    "        show_eye = not show_eye\n",
    "    elif key == ord('s'):\n",
    "        filename = f\"{SAVE_PREFIX}_{int(time.time())}_{save_count}.png\"\n",
    "        cv2.imwrite(filename, frame)\n",
    "        print(f\"Saved {filename}\")\n",
    "        save_count += 1\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90566acd-e3f0-4e48-902b-8ed901ac702a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
